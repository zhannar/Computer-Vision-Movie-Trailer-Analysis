{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Datasets to use:\n",
    "- User Movie Ratings & Movie Metadata\n",
    "- Trailers\n",
    "- Subjective - Visual Sentiment Training\n",
    "- Objective - Visual Description Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Movie Ratings & Movie Metadata\n",
    "\n",
    "- Movie Ratings Data derives from here: http://grouplens.org/datasets/movielens/\n",
    "10M Set (Number of Users = 72,000 users, Number of Movies = 10,000, Number of Ratings = 10,000,000 )\n",
    "Maximum: 10M Set (Number of Users = 240,000 users, Number of Movies = 33,000, Number of Ratings = 10,000,000 )\n",
    "(Number of Users = , Number of Movies = , Number of Ratings = )\n",
    "\n",
    "- 10M Set + IMBD/Rotten Tomatoes Data, which is actually used:\n",
    "(Note 1: Number of Users = 2,113, Number of Movies = 10,197, Number of Ratings = 855,598 )\n",
    "(Note 2: From the original dataset, only those users with both rating and tagging information have been mantained.\n",
    "(Note 3: Also, I could have chosen a dataset with more users but then I'd need to do more work to scrape data from IMDB and Rotten Tomatoes. Going to see if it's good enough as is...Also, with more movies will come more videos to scrape and that will take up more time to process and memory to store.\n",
    "\n",
    "Idea: One area for advancement could be using the expanded list of users (240k), but over the still limited amount of movies(10,197)\n",
    "http://grouplens.org/datasets/hetrec-2011/\n",
    "\n",
    "Description of Augmented Dataset: http://ir.ii.uam.es/hetrec2011/datasets.html\n",
    "\n",
    "### -  Trailers\n",
    "\n",
    "#### NO!! - http://movietrailer.co/movie/3723/Kung+Fu+Panda+2 ## Verdict: Negative - Movie Trailer not readily found.\n",
    "\n",
    "#### YES, but HARD!! - http://www.traileraddict.com/the-a-list/trailer ## Verdict - Relatively stable/even layout that's prime for scraping. Only problem is no ability to search by imdbID, and the movies are embedded so it may be hard to scrape. Embedded URL?:\n",
    "\n",
    "a) Prepare my list of film names\n",
    "-[DEFINITELY] make all lowercase\n",
    "-[MAYBE] maybe remove the word \"the\"\n",
    "- [DEFINITE] - Create alternate key appending movie title with year\n",
    "-[DEFINITE] - If now match found for regular movie name, append with year of creation and retry\n",
    "\n",
    "\n",
    "b) Scrape alll film names here:\n",
    "- http://www.traileraddict.com/thefilms\n",
    "- For each movie, need movie's website location\n",
    "- Individual Movie: http://www.traileraddict.com/sabrina    \n",
    "- Trailer of Movie: http://www.traileraddict.com/sabrina/trailer\n",
    "- On Trailer Page: Scrape the trailer + Metadata (ESPECIALLY YEAR! - Need to confirm for movies that don't have a year at the and of their website, that they are actually the right one... e.g. \n",
    "\n",
    "\"Sabrina\" in my list refers to the 1954 film, and likewise for Trailer Addict...but there is a 90's film with Harrison Ford that it also could have gotten mixed up with.\n",
    "\n",
    "In Movie Clip:\n",
    "<meta itemprop=\"embedUrl\" content=\"//v.traileraddict.com/emd/19414?id=19414\">\n",
    "\n",
    "#### YES, maybe easier - http://www.movie-list.com/ - # Verdict, seems friendly enough, and more transparent/less hoops to jump through.\n",
    "b) Scrape alll film names here: http://www.movie-list.com/archive.php\n",
    "- Go to this span: id = trailer (note: there may be id = trailer 2 -> that's not hte one you want\n",
    "- Get this linke: <a href=\"/embed.php?file=http://cdn.movie-list.com/flvideo/2335.mp4&amp;width=640&amp;height=390&amp;cap=gooddaytodiehardb&amp;iframe=true\" rel=\"prettyPhoto[iframes]\"><img src=\"http://www.movie-list.com/img/images/embed-off.png\" onmouseover=\"this.src='http://www.movie-list.com/img/images/embed-on.png'\" onmouseout=\"this.src='http://www.movie-list.com/img/images/embed-off.png'\" alt=\"Embed this trailer on your website\" title=\"Embed this trailer on your website\" height=\"35\" border=\"0\" width=\"165\"></a>\n",
    "\n",
    "- Extract out website: http://cdn.movie-list.com/flvideo/2335.mp4\n",
    "Note: it may be a different formate and may not present with http forst:\n",
    "cdn.movie-list.com/flvideo/1727.flv\n",
    "\n",
    "??Maybe just grap the href as a whole, and parse it later.\n",
    "\n",
    "\n",
    "https://www.wondershare.com/download/download-imdb-videos.html\n",
    "http://www.real.com/resources/movie-trailer-downloads/\n",
    "\n",
    "\n",
    "### -  Subjective - Visual Sentiment Training\n",
    "Summary Paper: http://www.ee.columbia.edu/ln/dvmm/vso/download/visual_sentiment_ontology_FINAL.pdf\n",
    "Website Overview: \n",
    "http://www.ee.columbia.edu/ln/dvmm/vso/download/sentibank.html\n",
    "\n",
    "1) VSO: Construct a large-scale Visual Sentiment Ontology (VSO) consisting of more than 3,000 Adjective Noun Pairs (ANP).\n",
    "a) Ontology & Concepts:\n",
    "....\n",
    "b)  Image Dataset (Flickr)\n",
    "....\n",
    "\n",
    "2) SENTIBANK: Second, we propose SentiBank, a novel visual concept detector library that can be used to detect the presence of 1,200 ANPs in an image.\n",
    "a) SentiBank: Visual Sentiment Concept Classifiers\n",
    "b) Photo Tweet Sentiment Benchmark\n",
    "\n",
    "\n",
    "### -  Objective - Visual Description Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Algorithms to use:\n",
    "- Download Movies from Web\n",
    "- Split Video into Frames\n",
    "- Neural Nets for Visual Sentiment Training\n",
    "- Neural Nets for Visual Descriptive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Movies from Web\n",
    "\n",
    "Here are some options / avenues I've collected to investigate:\n",
    "(Definitely Youtube, not sure if others as well)\n",
    "- https://www.reddit.com/r/Python/comments/4283zd/a_python_script_to_download_all_videos_in_a/\n",
    "\n",
    "- http://www.wikihow.com/Install-YouTube-DL.py-to-Download-YouTube-Videos-to-Your-PC\n",
    "- https://github.com/rg3/youtube-dl/\n",
    "- https://simplypython.wordpress.com/2015/07/16/search-and-download-youtube-videos-using-python/\n",
    "[NOT IDEAL!] Maybe go to some site like \"youtubetomp4\" and manually enter it in each time...\n",
    "\n",
    "#### Scraping Iframes:\n",
    "http://stackoverflow.com/questions/26677609/scraping-iframe-video-from-other-sites-through-php\n",
    "http://stackoverflow.com/questions/7481699/how-to-scrape-website-content-complex-iframe-javascript-submission\n",
    "\n",
    "#### Downloading JW ??\n",
    "https://www.youtube.com/watch?v=z9woWS0WHOE\n",
    "http://stackoverflow.com/questions/35013400/script-to-scrape-crawl-streaming-url-from-site-and-jw-player\n",
    "http://www.warriorforum.com/website-design/216215-how-do-you-capture-video-jw-player.html\n",
    "https://filippo.io/scraping-a-video-out-of-a-more-stubborn-site/\n",
    "\n",
    "### Split Video into Frames\n",
    "Here are some options / avenues I've collected to investigate:\n",
    "(The first 2/3 seem to be REALLY helpful)\n",
    "- https://tobilehman.com/blog/2013/01/20/extract-array-of-frames-from-mp4-using-python-opencv-bindings/\n",
    "- http://superuser.com/questions/135117/how-to-convert-video-to-images\n",
    "- http://stackoverflow.com/questions/28625667/convert-video-into-individual-frames-using-python-without-ffmpeg\n",
    "- http://stackoverflow.com/questions/10672578/extract-video-frames-in-python\n",
    "- http://stackoverflow.com/questions/18954889/how-to-process-images-of-a-video-frame-by-frame-in-video-streaming-using-opencv\n",
    "\n",
    "\n",
    "### Neural Nets for Visual Sentiment Training\n",
    "### Neural Nets for Visual Descriptive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Trailer Specific Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Movie Trailer Scraping & Parsing\n",
    "\n",
    "## - Feature Engineering - Exotic/Advanced: Neural Netorks for Image Captioning\n",
    "Goal: Generate a string of description for each individual frame in the trailer.\n",
    "\n",
    "## - Feature Engineering - Exotic/Advanced: Neural Netorks for Visual Sentiment Analysis\n",
    "\n",
    "Goal: Generate a string of sentiments which is a combination of sentiments for each individual frame in the trailer.\n",
    "\n",
    "\n",
    "## - Other random thoughs\n",
    "- AUDIO - Scrape the audio files of the movies -> Send to magic api which will code them for features\n",
    "?? Maybe take the trailer -> extract audio -> use \"librosa\" library and then measure similarity betweeen the tracks?\n",
    "\n",
    "https://github.com/bmcfee/librosa\n",
    "\n",
    "- Can I incorporate word2vec in some way...\n",
    "a) tags associated with movies -- vector of tags\n",
    "b) Maybe around the plot? \n",
    "c) The trailer descriptions extracted from Neural Networks\n",
    "d) IMDB Movie Descriptions\n",
    "e) Wikipedia articles\n",
    "\n",
    "\n",
    "- Can I incorpoate some of the specified methods employed in the Netflix prize?\n",
    "\n",
    "- Can I introduce some time series analysis of things?\n",
    "- Explore what movies get dropped due to NA's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Resources\n",
    "\n",
    "- Does Convolutional neural networks (ConvNets) on Movie Posters to predict if a movie will be good or bad: http://www.strong.io/blog/movie-posters-deep-neural-networks\n",
    "- Uses neural networks to classify movie clips into genres: action, horror, comedy, music and drama genres.http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5291884&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5291884\n",
    "- Why to use movie clips instead of movie trailers: http://geektyrant.com/news/5-reasons-why-you-should-watch-movie-clips-instead-of-trailers\n",
    "- Depository of Movie Clips instead of Movie Trailers: http://www.wingclips.com/themes/abolition\n",
    "\n",
    "- Takes spoken audio (spontaneous, from youtube), converts it to text and parses it for sentiment: http://www.utd.edu/~john.hansen/Publications/CP-ICASSP13-KaushikSangwanHansen-Sentiment-0008485.pdf\n",
    "- convert audio to text using a speech2text api: https://speech-to-text-demo.mybluemix.net/\n",
    "- An API for sentiment analysis, like this one for English (SentiFindr API Documentation) or for Russian (RussianSentimentAnalyzer API Documentation) (Chinese is coming soon. Update: it came: Chinese sentiment analysis: Fuxi API)\n",
    "\n",
    "# Wikipedia - API:\n",
    "Films by Year: https://en.wikipedia.org/wiki/Lists_of_films#By_year), scrape the list of movies by year.\n",
    "API: https://www.mediawiki.org/wiki/API:Main_page\n",
    "\n",
    "\n",
    "\n",
    "# WORD2VEC Stuff\n",
    "* Some articles on using word2vec for clustering:\n",
    "http://www.kdnuggets.com/2015/04/math-ideas-word-worth-thousand-vectors.html\n",
    "http://douglasduhaime.com/blog/clustering-semantic-vectors-with-python\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors\n",
    "https://github.com/wendykan/DeepLearningMovies/blob/master/Word2Vec_BagOfCentroids.py\n",
    "http://www.sersc.org/journals/IJGDC/vol7_no3/5.pdf\n",
    "http://blog.stuart.axelbrooke.com/instagram-similar-tag-discovery/\n",
    "\n",
    "http://imdbpy.sourceforge.net/docs/README.keywords.txt\n",
    "http://imdbpy.sourceforge.net/downloads.html#source-code\n",
    "http://opendata.stackexchange.com/questions/1073/where-to-get-imdb-datasets\n",
    "http://cs229.stanford.edu/proj2012/HelmerJi-FilmClassificationByTrailerFeatures.pdf \n",
    "http://cs229.stanford.edu/proj2011/ApteForssellSidhwa-PredictingMovieRevenue.pdf \n",    
    "\n",
    "\n",    
    "\n",
    "\n",    
    "# Recomenders\n",
    "\"MovieLens.Several machine learning related algorithms â€“ baseline predictor, KNN, Stochastic Gradient Descent, SVD, SVD++,\n",
    "asymmetric SVD, integrated model and NMTF are used to\n",
    "predict the rating from particular users for unrated movies.\n",
    "RMSE (Root-Mean-Square-Error) is applied as the main\n",
    "criteria to evaluate their performance.\"http://cs229.stanford.edu/proj2012/BaoXia-MovieRatingEstimationAndRecommendation_FinalWriteup.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
